// $ANTLR : "arff.g" -> "ArffParser.java"$

    package carmen.learning.io;
    import carmen.*;
    import carmen.networks.*;
    import carmen.networks.constraints.compound.*;
	import carmen.io.networks.LogFile;
    import java.util.*;

import antlr.TokenBuffer;
import antlr.TokenStreamException;
import antlr.TokenStreamIOException;
import antlr.ANTLRException;
import antlr.LLkParser;
import antlr.Token;
import antlr.TokenStream;
import antlr.RecognitionException;
import antlr.NoViableAltException;
import antlr.MismatchedTokenException;
import antlr.SemanticException;
import antlr.ParserSharedInputState;
import antlr.collections.impl.BitSet;
import antlr.collections.AST;
import java.util.Hashtable;
import antlr.ASTFactory;
import antlr.ASTPair;
import antlr.collections.impl.ASTArray;

public class ArffParser extends antlr.LLkParser       implements ArffLexerTokenTypes
 {

	/** Global variable */
	private ArrayList<Variable> fsVariables = new ArrayList<Variable>();

	/** Global variable to store the variables while they are reading from
	 * an input file */
	private ProbNet probNet = PNFactories.getEmptyBN();

	private ProbNet bayesNet = PNFactories.getEmptyBN(); 

	/** Stores information about Elvira nets */
	private HashMap<String, Object> ioNet = new HashMap<String, Object>();
	
	private int casesCont = 0;
	
	private int[][] cases;
	
	private ArrayList<int[]> casesAux; //we know the number of cases while reading
	
	private int[] example;

	private ArrayList<String> statesVar;
	
	private int index=0;
	
	/** Importance of messages generated by the parser. Initially the minimum */
	private int messagesImportance = 2;

	/** Default states. Global variable */
	private String[] defaultStates;
	
	/** A utility node has no states, for computational reasons we define a
      * set of one state */
	private String[] defaultUtilityStates={""};
	
	/** Messages file */
	private LogFile logFile;
	
	/** @param logFile */
	public void setLogFile(LogFile logFile) {
		this.logFile = logFile;
		probNet.setLogFile(logFile);
	}
	
	// Chance = Potential; Utility = utility
	private NodeType kindRelation = NodeType.CHANCE;  
	
    /** Adds a <code>ProbNode</code> to the <code>ProbNet</code>. */
	public ProbNode addProbNode(HashMap<String, Object> ioNet, 
			HashMap<String, Object> infoNode, String nodeName) {

		Variable fsVariable = null;
		if (infoNode != null) {
			if (infoNode.get("NodeStates") != null) {
				fsVariable = new Variable(nodeName, 
					(String[])infoNode.get("NodeStates"));
			} else {
				fsVariable = new Variable(nodeName, (String[])ioNet
					.get("DefaultNodeStates"));
			}
		}
		ProbNode probNode = null;
		try {
			probNode = probNet.addVariable(fsVariable, 
				(NodeType)infoNode.get("NodeType"));
			probNode.properties = infoNode;
			infoNode.put("ProbNode", probNode);
		} catch (Exception e) {
			System.err.println(e.getMessage());
			e.printStackTrace();
		}
		return probNode;
	}
	
	/** Sets the importance of messages generated by the parser
	 * @param importance */
	public void setMessagesImportance(int importance) {
		messagesImportance = importance;
	}
	
	public ProbNet getProbNet(){
		return probNet;
	}
	
	public int[][] getCases(){
		return cases;
	}

protected ArffParser(TokenBuffer tokenBuf, int k) {
  super(tokenBuf,k);
  tokenNames = _tokenNames;
  buildTokenTypeASTClassMap();
  astFactory = new ASTFactory(getTokenTypeToASTClassMap());
}

public ArffParser(TokenBuffer tokenBuf) {
  this(tokenBuf,7);
}

protected ArffParser(TokenStream lexer, int k) {
  super(lexer,k);
  tokenNames = _tokenNames;
  buildTokenTypeASTClassMap();
  astFactory = new ASTFactory(getTokenTypeToASTClassMap());
}

public ArffParser(TokenStream lexer) {
  this(lexer,7);
}

public ArffParser(ParserSharedInputState state) {
  super(state,7);
  tokenNames = _tokenNames;
  buildTokenTypeASTClassMap();
  astFactory = new ASTFactory(getTokenTypeToASTClassMap());
}

	public final HashMap<String, Object>  relation() throws RecognitionException, TokenStreamException {
		HashMap<String, Object> bn=null;
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST relation_AST = null;
		Token  b = null;
		AST b_AST = null;
		Token  s1 = null;
		AST s1_AST = null;
		Token  s2 = null;
		AST s2_AST = null;
		
			String name = null;
			double visualprecisionNet = Double.MIN_VALUE, versionNet = Double.MIN_VALUE;
			
			probNet.properties = ioNet;
		ioNet.put("BayesNet", bayesNet);
		ioNet.put("ProbNet", bayesNet);
		probNet = bayesNet;
		
		
		try {      // for error handling
			b = LT(1);
			b_AST = astFactory.create(b);
			astFactory.makeASTRoot(currentAST, b_AST);
			match(RELATION);
			{
			switch ( LA(1)) {
			case IDENT:
			{
				s1 = LT(1);
				s1_AST = astFactory.create(s1);
				astFactory.addASTChild(currentAST, s1_AST);
				match(IDENT);
				break;
			}
			case STRING:
			{
				s2 = LT(1);
				s2_AST = astFactory.create(s2);
				astFactory.addASTChild(currentAST, s2_AST);
				match(STRING);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			attributes();
			astFactory.addASTChild(currentAST, returnAST);
			data();
			astFactory.addASTChild(currentAST, returnAST);
			
				
				if(s1!=null)
					name = s1.getText();
				else
					name = s2.getText();
			ioNet.put("Name", name);
			
			if (messagesImportance >= logFile.importanceThreshold) {
					logFile.write("Bayes net name: " + name);
					logFile.write("--------------------------");
			}
				bn = ioNet; 
			
			relation_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_0);
		}
		returnAST = relation_AST;
		return bn;
	}
	
	public final void attributes() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST attributes_AST = null;
		
		try {      // for error handling
			
				fsVariables = new ArrayList<Variable>();
			
			{
			int _cnt268=0;
			_loop268:
			do {
				if ((LA(1)==ATTRIBUTE)) {
					attribute();
					astFactory.addASTChild(currentAST, returnAST);
				}
				else {
					if ( _cnt268>=1 ) { break _loop268; } else {throw new NoViableAltException(LT(1), getFilename());}
				}
				
				_cnt268++;
			} while (true);
			}
			
				int numVariables = probNet.getChanceAndDecisionVariables().size();
			
				casesAux = new ArrayList<int[]>();
				example = new int[numVariables];
				
			for (int i=0; i<numVariables; i++)
			fsVariables.add(probNet.getChanceAndDecisionVariables().get(i));
				
				Variable fsVariable;
				for (int i = numVariables-1; i >= 0; i--) {
					fsVariable = fsVariables.get(i);
				String[] states = fsVariable.getStates();
				if (messagesImportance >= logFile.importanceThreshold) {
					    logFile.write("Variable " + fsVariable.getName() + " states: ");
				}
				for (int j = 0; j < states.length; j++) {
					    if (messagesImportance >= logFile.importanceThreshold) {
				    		logFile.write(states[j] + " ");
					    }
				}
				    if (messagesImportance >= logFile.importanceThreshold) {
					logFile.write("");
				    }
			/*	    try {
				    probNet.addVariable(fsVariables.get(i), NodeType.CHANCE);
				} catch (Exception e) {
					System.err.println("Problems creating BayesNet");
					    System.err.println(e.getMessage());
				    }		*/
				}
			
			attributes_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_1);
		}
		returnAST = attributes_AST;
	}
	
	public final void data() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST data_AST = null;
		
		try {      // for error handling
			match(DATA);
			{
			_loop279:
			do {
				if ((LA(1)==IDENT||LA(1)==STRING)) {
					example();
					astFactory.addASTChild(currentAST, returnAST);
				}
				else {
					break _loop279;
				}
				
			} while (true);
			}
				
				cases = new int[casesAux.size()][probNet.getChanceAndDecisionVariables().size()];
				for (int i=0; i< casesAux.size(); i++)
					cases[i] = casesAux.get(i);
			
			data_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_0);
		}
		returnAST = data_AST;
	}
	
	public final void attribute() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST attribute_AST = null;
		Token  n = null;
		AST n_AST = null;
		Token  id1 = null;
		AST id1_AST = null;
		Token  id2 = null;
		AST id2_AST = null;
		HashMap<String, Object> infoNode = null; 
				statesVar = new ArrayList<String>();
		
		try {      // for error handling
			n = LT(1);
			n_AST = astFactory.create(n);
			astFactory.makeASTRoot(currentAST, n_AST);
			match(ATTRIBUTE);
			{
			switch ( LA(1)) {
			case IDENT:
			{
				id1 = LT(1);
				id1_AST = astFactory.create(id1);
				match(IDENT);
				break;
			}
			case STRING:
			{
				id2 = LT(1);
				id2_AST = astFactory.create(id2);
				match(STRING);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			states();
			astFactory.addASTChild(currentAST, returnAST);
			
			
				NodeType typeOfNode=NodeType.CHANCE;
				infoNode = new HashMap<String, Object>();
				ProbNode probNode;
				String[] states = new String[statesVar.size()];
				int i=0;
				for(String state : statesVar){
					states[i] = statesVar.get(i);
					i++;
				}
				infoNode.put("NodeStates",states); 
				infoNode.put("NodeType", typeOfNode);
				if (id1 != null)
					infoNode.put("Name", id1.getText());
				else
					infoNode.put("Name", id2.getText());
				infoNode.put("UseDefaultStates", new Boolean(false));
				infoNode.put("CoordinateX", 0);
				infoNode.put("CoordinateY", 0);
				infoNode.put("TypeOfVariable", VariableType.DISCRETE);
				if(id1 != null)
					probNode = addProbNode(ioNet, infoNode, id1.getText());
				else
					probNode = addProbNode(ioNet, infoNode, id2.getText());
				infoNode.put("ProbNode", probNode);
			
			if (messagesImportance >= logFile.importanceThreshold) {
				    logFile.write(n.getText());
			}
			
			//	Variable fsVariable = null;
			if (infoNode != null) {
			//    	fsVariable = new Variable(id.getText(), infoNode.getStates());
				    if (messagesImportance >= logFile.importanceThreshold) {
				    	if (infoNode.get("NodeStates") != null) {
				    	logFile.write(". Num states: " + 
				    	((String[])infoNode.get("NodeStates")).length);
				    	}
				    }
			} else {
			//    	fsVariable = new Variable(id.getText(),defaultStates);
				    if (messagesImportance >= logFile.importanceThreshold) {
				    logFile.write(". Num states: "+defaultStates.length);
				    }
			} 
			//    fsVariables.add(fsVariable);
				probNode.properties = infoNode;
			
			attribute_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_2);
		}
		returnAST = attribute_AST;
	}
	
	public final void states() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST states_AST = null;
		Token  lb = null;
		AST lb_AST = null;
		Token  c = null;
		AST c_AST = null;
		Token  rb = null;
		AST rb_AST = null;
		
		try {      // for error handling
			lb = LT(1);
			lb_AST = astFactory.create(lb);
			match(LEFTB);
			state();
			{
			_loop273:
			do {
				if ((LA(1)==COMMA)) {
					c = LT(1);
					c_AST = astFactory.create(c);
					match(COMMA);
					state();
				}
				else {
					break _loop273;
				}
				
			} while (true);
			}
			rb = LT(1);
			rb_AST = astFactory.create(rb);
			match(RIGHTB);
			states_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_2);
		}
		returnAST = states_AST;
	}
	
	public final void state() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST state_AST = null;
		Token  s = null;
		AST s_AST = null;
		Token  i = null;
		AST i_AST = null;
		
		try {      // for error handling
			switch ( LA(1)) {
			case STRING:
			{
				{
				s = LT(1);
				s_AST = astFactory.create(s);
				astFactory.addASTChild(currentAST, s_AST);
				match(STRING);
				}
				state_AST = (AST)currentAST.root;
				break;
			}
			case IDENT:
			{
				{
				i = LT(1);
				i_AST = astFactory.create(i);
				astFactory.addASTChild(currentAST, i_AST);
				match(IDENT);
				}
				
				//state : (i:IDENT) {
					if (s==null)
						statesVar.add(i.getText());
					else
						statesVar.add(s.getText());
				
				state_AST = (AST)currentAST.root;
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_3);
		}
		returnAST = state_AST;
	}
	
	public final void example() throws RecognitionException, TokenStreamException {
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST example_AST = null;
		
		try {      // for error handling
			{
			_loop282:
			do {
				if ((LA(1)==IDENT||LA(1)==STRING) && (LA(2)==COMMA)) {
					caseData();
					astFactory.addASTChild(currentAST, returnAST);
					match(COMMA);
				}
				else {
					break _loop282;
				}
				
			} while (true);
			}
			caseData();
			astFactory.addASTChild(currentAST, returnAST);
			
				index=0;
				casesAux.add(example);
				casesCont++;
				example = new int[probNet.getChanceAndDecisionVariables().size()];
			
			example_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_4);
		}
		returnAST = example_AST;
	}
	
	public final int  caseData() throws RecognitionException, TokenStreamException {
		int result=0;
		
		returnAST = null;
		ASTPair currentAST = new ASTPair();
		AST caseData_AST = null;
		Token  l1 = null;
		AST l1_AST = null;
		Token  l2 = null;
		AST l2_AST = null;
		
		try {      // for error handling
			{
			switch ( LA(1)) {
			case IDENT:
			{
				l1 = LT(1);
				l1_AST = astFactory.create(l1);
				astFactory.addASTChild(currentAST, l1_AST);
				match(IDENT);
				break;
			}
			case STRING:
			{
				l2 = LT(1);
				l2_AST = astFactory.create(l2);
				astFactory.addASTChild(currentAST, l2_AST);
				match(STRING);
				break;
			}
			default:
			{
				throw new NoViableAltException(LT(1), getFilename());
			}
			}
			}
			
				if (l1!=null)
					example[index] = fsVariables.get(index).getStateIndex(l1.getText());
				else
					example[index] = fsVariables.get(index).getStateIndex(l2.getText());
				index++;
			
			caseData_AST = (AST)currentAST.root;
		}
		catch (RecognitionException ex) {
			reportError(ex);
			recover(ex,_tokenSet_5);
		}
		returnAST = caseData_AST;
		return result;
	}
	
	
	public static final String[] _tokenNames = {
		"<0>",
		"EOF",
		"<2>",
		"NULL_TREE_LOOKAHEAD",
		"QUOTATION",
		"COMMA",
		"LEFTB",
		"RIGHTB",
		"WHITE",
		"REMARK",
		"SEPARATOR",
		"IDENT",
		"STRING",
		"RELATION",
		"ATTRIBUTE",
		"DATA"
	};
	
	protected void buildTokenTypeASTClassMap() {
		tokenTypeToASTClassMap=null;
	};
	
	private static final long[] mk_tokenSet_0() {
		long[] data = { 2L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_0 = new BitSet(mk_tokenSet_0());
	private static final long[] mk_tokenSet_1() {
		long[] data = { 32768L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_1 = new BitSet(mk_tokenSet_1());
	private static final long[] mk_tokenSet_2() {
		long[] data = { 49152L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_2 = new BitSet(mk_tokenSet_2());
	private static final long[] mk_tokenSet_3() {
		long[] data = { 160L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_3 = new BitSet(mk_tokenSet_3());
	private static final long[] mk_tokenSet_4() {
		long[] data = { 6146L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_4 = new BitSet(mk_tokenSet_4());
	private static final long[] mk_tokenSet_5() {
		long[] data = { 6178L, 0L};
		return data;
	}
	public static final BitSet _tokenSet_5 = new BitSet(mk_tokenSet_5());
	
	}
